{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46c5a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05a0d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#데이터의 사이즈를 28x28의 사이즈로 각각 바꿔서 저장한다.\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87225f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4318b5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2d65428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 216\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#바뀐 가위,바위,보 의 데이터300개를 x_train,y_train데이터에 (학습데이터)에 할당해준다.\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "#이미지데이터의 최솟값,최댓값을 확인후 0,1사이의 정규화를 통해 데이터를 정규화 시켜준다.\n",
    "\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4043f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9ab50c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "# model.add(Dropout(0.25))# Dropout 추가 # 드롭아웃을 합성곱층마다 실행했더니 오히려 정확도가 떨어져서 값을 조정해도 나아지지않아 처음층의 드롭아웃은 안하기로함.\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25)) # Dropout 추가\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4d82c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 6.9283 - accuracy: 0.3067\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.7926 - accuracy: 0.3633\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.2191 - accuracy: 0.3967\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.0634 - accuracy: 0.4067\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.9631 - accuracy: 0.5533\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8857 - accuracy: 0.5500\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8414 - accuracy: 0.6300\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7743 - accuracy: 0.6267\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7438 - accuracy: 0.6567\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8294 - accuracy: 0.6233\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7215 - accuracy: 0.6633\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7348 - accuracy: 0.6400\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6886 - accuracy: 0.6733\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6260 - accuracy: 0.7167\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6404 - accuracy: 0.7067\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6972 - accuracy: 0.7167\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6265 - accuracy: 0.7267\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5540 - accuracy: 0.7700\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5845 - accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5579 - accuracy: 0.7667\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4898 - accuracy: 0.8233\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4981 - accuracy: 0.8000\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5268 - accuracy: 0.7767\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5262 - accuracy: 0.7867\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4617 - accuracy: 0.8167\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4077 - accuracy: 0.8400\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3636 - accuracy: 0.8600\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3254 - accuracy: 0.8800\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4463 - accuracy: 0.8567\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5439 - accuracy: 0.7833\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_113 (Conv2D)          (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 27,939\n",
      "Trainable params: 27,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "x_train_reshaped=x_train.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "#처음에 reshape(-1.28,28,1)을 설정 했는대 reshape의 의미를 알고 컬러이미지이니rgb색상에 맞추어 3으로 바꿔주었더니 오류가 사라졌다.\n",
    "#x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=30)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "39648d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "#test데이터가 있는 경로에 이미지 파일들을 각각 불러와서 resized시킨다.\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dba37575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.1274 - accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "#10/10 - 0s - loss: 1.1013 - accuracy: 0.3333->계속 시도했던 오차와 정확도, 데이터의 수가 적어서 그런지 0.3333에서 거의 변동이 없다가\n",
    "#드롭아웃과 dense레이어의 채널수를 64로 늘린뒤 \n",
    "#처음에 0.33에서 더 안나아졌는대 지금은 10/10 - 0s - loss: 1.0981 - accuracy: 0.3600까지 정확도가 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ab0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2c22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
